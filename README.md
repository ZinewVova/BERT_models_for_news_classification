В данной работе был проведён сравнительный анализ различных моделей для задачи многоклассовой классификации текстов.
Используется набор статей AG News, который содержит заголовки и тексты новостных статей, разделенные на четыре категории:
  * World (Мир)
  * Sports (Спорт)
  * Business (Бизнес)
  * Sci/Tech (Наука/Технологии)
    

Этапы работы
1. Предобработка текста
2. Векторизация текста с помощью Bag of Word и TF-IDF
3. Обучение моделей
   
Были обучены и оценены следующие модели:


### *Классические модели машинного обучения*:

| Классификатор | BOW-TEST | BOW-TRAIN | TF-IDF-TEST | TF-IDF-TRAIN |
| --- | --- | --- | --- | --- |
| Наивный Байесовский классификатор | 0.831 | 0.954 | 0.833 | 0.952 |
| Метод опорных векторов (SVM) | 0.790 | 0.983 | 0.826 | 0.996 |
| Метод k ближайших соседей (k-NN) | 0.478 | 0.721 | 0.757 | 0.861 |
| Случайный лес | 0.746 | 1.000 | 0.745 | 1.000 |
| Градиентный бустинг | 0.752 | 0.970 | 0.739 | 0.988 |


### *Нейронные сети и трансформеры*:

| Классификатор | Accuracy TEST |
| --- | --- |
| Полносвязная НС | 0.82 |
| Word2Vec + LSTM | 0.895 |
| BERT | 0.904 |
| RoBERTa | 0.917 |
| electra | 0.909 |
|DeBERTa | 0.904|


**Результаты**
Модели на основе трансформеров (BERT, RoBERTa и др.) показали наилучшие результаты, достигнув точности около 90% на тестовой выборке. Это значительно превосходит классические модели машинного обучения, точность которых составила около 83% для наилучшей из них (Наивный Байес на TF-IDF).
