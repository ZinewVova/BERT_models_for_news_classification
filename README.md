В данной работе был проведён сравнительный анализ различных моделей для задачи многоклассовой классификации текстов.
Используется набор статей AG News, который содержит заголовки и тексты новостных статей, разделенные на четыре категории:
  * World (Мир)
  * Sports (Спорт)
  * Business (Бизнес)
  * Sci/Tech (Наука/Технологии)
    

Этапы работы
1. Предобработка текста
2. Векторизация текста с помощью Bag of Word и TF-IDF
3. Обучение моделей
   
Были обучены и оценены следующие модели:


  *Классические модели машинного обучения*:
* Наивный байесовский классификатор
* Метод опорных векторов (SVM)
* Метод k-ближайших соседей (k-NN)
* Случайный лес (Random Forest)
* Градиентный бустинг (Gradient Boosting)


*Нейронные сети и трансформеры*:
* Простая полносвязная НС
* Рекуррентная нейронная сеть (RNN/LSTM) с эмбеддингами Word2Vec
* BERT (bert-base-uncased)
* RoBERTa (FacebookAI/roberta-base)
* ELECTRA (google/electra-base-discriminator)
* DeBERTa (microsoft/deberta-base)


**Результаты**
Модели на основе трансформеров (BERT, RoBERTa и др.) показали наилучшие результаты, достигнув точности около 90% на тестовой выборке. Это значительно превосходит классические модели машинного обучения, точность которых составила около 83% для наилучшей из них (Наивный Байес на TF-IDF).
