В данной работе был проведён сравнительный анализ различных моделей для задачи многоклассовой классификации текстов.
Используется набор статей AG News, который содержит заголовки и тексты новостных статей, разделенные на четыре категории:
  * World (Мир)
  * Sports (Спорт)
  * Business (Бизнес)
  * Sci/Tech (Наука/Технологии)
    

Этапы работы
1. Предобработка текста
2. Векторизация текста с помощью Bag of Word и TF-IDF
3. Обучение моделей
   
Были обучены и оценены следующие модели:


  *Классические модели машинного обучения*:
* Наивный байесовский классификатор
* Метод опорных векторов (SVM)
* Метод k-ближайших соседей (k-NN)
* Случайный лес (Random Forest)
* Градиентный бустинг (Gradient Boosting)

### Результаты обучения (accuracy)

| Классификатор | BOW-TEST | BOW-TRAIN | TF-IDF-TEST | TF-IDF-TRAIN |
| --- | --- | --- | --- | --- |
| Наивный Байесовский классификатор | 0.831 | 0.954 | 0.833 | 0.952 |
| Метод опорных векторов (SVM) | 0.790 | 0.983 | 0.826 | 0.996 |
| Метод k ближайших соседей (k-NN) | 0.478 | 0.721 | 0.757 | 0.861 |
| Случайный лес | 0.746 | 1.000 | 0.745 | 1.000 |
| Градиентный бустинг | 0.752 | 0.970 | 0.739 | 0.988 |


*Нейронные сети и трансформеры*:
* Простая полносвязная НС
* Рекуррентная нейронная сеть (RNN/LSTM) с эмбеддингами Word2Vec
* BERT (bert-base-uncased)
* RoBERTa (FacebookAI/roberta-base)
* ELECTRA (google/electra-base-discriminator)
* DeBERTa (microsoft/deberta-base)


**Результаты**
Модели на основе трансформеров (BERT, RoBERTa и др.) показали наилучшие результаты, достигнув точности около 90% на тестовой выборке. Это значительно превосходит классические модели машинного обучения, точность которых составила около 83% для наилучшей из них (Наивный Байес на TF-IDF).
